{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JiF2J--Bm5c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define paths for train and test directories\n",
        "train_dir = '/content/drive/MyDrive/Dataset/Resized/train'\n",
        "test_dir = '/content/drive/MyDrive/Dataset/Resized/test'\n",
        "\n",
        "# Create train and test directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "print(\"Train and test directories created successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define paths\n",
        "main_dataset_dir = '/content/drive/MyDrive/Dataset/Resized'\n",
        "train_dir = '/content/drive/MyDrive/Dataset/Resized/train'\n",
        "test_dir = '/content/drive/MyDrive/Dataset/Resized/test'\n",
        "\n",
        "# Create train and test directories if they don't exist\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Define the ratio for splitting (e.g., 80% train, 20% test)\n",
        "train_ratio = 0.8\n",
        "\n",
        "# Iterate over each class directory in the main dataset directory\n",
        "for class_dir in os.listdir(main_dataset_dir):\n",
        "    class_path = os.path.join(main_dataset_dir, class_dir)\n",
        "    if os.path.isdir(class_path):\n",
        "        # Get list of image filenames in the class directory\n",
        "        images = [f for f in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, f))]\n",
        "\n",
        "        # Shuffle the images to make sure randomness\n",
        "        random.shuffle(images)\n",
        "\n",
        "        # Calculate split indices\n",
        "        split_index = int(len(images) * train_ratio)\n",
        "\n",
        "        # Split images into train and test sets\n",
        "        train_images = images[:split_index]\n",
        "        test_images = images[split_index:]\n",
        "\n",
        "        # Move images to train directory\n",
        "        for image in train_images:\n",
        "            src = os.path.join(class_path, image)\n",
        "            dst = os.path.join(train_dir, class_dir, image)\n",
        "            os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "        # Move images to test directory\n",
        "        for image in test_images:\n",
        "            src = os.path.join(class_path, image)\n",
        "            dst = os.path.join(test_dir, class_dir, image)\n",
        "            os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "            shutil.copy(src, dst)\n",
        "\n",
        "print(\"Dataset split into train and test sets successfully.\")\n"
      ],
      "metadata": {
        "id": "n2y-69C4Bn8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the parent folder path\n",
        "parent_folder = '/content/drive/MyDrive/Dataset/Resized/train'\n",
        "\n",
        "# Function to count the number of image files in a directory\n",
        "def count_images(directory):\n",
        "    count = sum(1 for file in os.listdir(directory) if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')))\n",
        "    return count\n",
        "\n",
        "# Iterate through each subdirectory of the parent folder\n",
        "for subdir in os.listdir(parent_folder):\n",
        "    subdir_path = os.path.join(parent_folder, subdir)\n",
        "    if os.path.isdir(subdir_path):\n",
        "        num_images = count_images(subdir_path)\n",
        "        print(f\"Number of images in '{subdir}': {num_images}\")\n"
      ],
      "metadata": {
        "id": "KaBn0qi0BqfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Specify the directory containing your images\n",
        "dataset_dir = \"/content/drive/MyDrive/Dataset/Resized\"\n",
        "\n",
        "# Iterate over each subfolder\n",
        "for subdir, _, files in os.walk(dataset_dir):\n",
        "    # Iterate over each file in the subfolder\n",
        "    for file_name in files:\n",
        "        # Check if the file is an image (you may need to adjust this condition depending on your file types)\n",
        "        if file_name.endswith(\".jpg\") or file_name.endswith(\".png\") or file_name.endswith(\".jpeg\"):\n",
        "            # Open the image file\n",
        "            img = Image.open(os.path.join(subdir, file_name))\n",
        "\n",
        "            # Get dimensions of the image\n",
        "            width, height = img.size\n",
        "\n",
        "            # Print dimensions\n",
        "            print(f\"Image: {os.path.join(subdir, file_name)}, Dimensions: {width}x{height}\")\n"
      ],
      "metadata": {
        "id": "1zTNu2g3Bswf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define paths for train and test directories\n",
        "train_dir = '/content/drive/MyDrive/Dataset/Resized/train'\n",
        "test_dir = '/content/drive/MyDrive/Dataset/Resized/test'\n",
        "\n",
        "# Function to count the number of files in a directory\n",
        "def count_files(directory):\n",
        "    count = sum(len(files) for _, _, files in os.walk(directory))\n",
        "    return count\n",
        "\n",
        "# Count the number of images in train and test directories\n",
        "train_image_count = count_files(train_dir)\n",
        "test_image_count = count_files(test_dir)\n",
        "\n",
        "print(\"Number of images in train directory:\", train_image_count)\n",
        "print(\"Number of images in test directory:\", test_image_count)\n"
      ],
      "metadata": {
        "id": "v2yfSa64BvDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from skimage import io\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Define paths for train and test directories\n",
        "train_dir = '/content/drive/MyDrive/Dataset/Resized/train'\n",
        "test_dir = '/content/drive/MyDrive/Dataset/Resized/test'\n",
        "\n",
        "# Function to extract features from images in a directory\n",
        "def extract_features_from_directory(directory):\n",
        "    features = []\n",
        "    labels = []\n",
        "    for class_label in os.listdir(directory):\n",
        "        class_dir = os.path.join(directory, class_label)\n",
        "        if os.path.isdir(class_dir):\n",
        "            for filename in os.listdir(class_dir):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                if os.path.isfile(img_path):  # Check if it's a file\n",
        "                    img = io.imread(img_path)\n",
        "                    features.append(img.flatten())  # Flatten image into a feature vector\n",
        "                    labels.append(class_label)\n",
        "                else:\n",
        "                    print(f\"Warning: {img_path} is not a valid file.\")\n",
        "    return features, labels\n",
        "\n",
        "# Extract features and labels from training data\n",
        "train_features, train_labels = extract_features_from_directory(train_dir)\n",
        "test_features, test_labels = extract_features_from_directory(test_dir)\n",
        "\n",
        "# Convert labels into numerical values\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "\n",
        "# Train the Random Forest model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(train_features, train_labels_encoded)\n",
        "\n",
        "# Predict labels for test data\n",
        "test_predictions_encoded = rf_model.predict(test_features)\n",
        "\n",
        "# Decode predicted labels\n",
        "test_predictions = label_encoder.inverse_transform(test_predictions_encoded)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, test_predictions)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "tW_J64EsBzOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Specify the path to save the pickle file in Google Drive\n",
        "pickle_file_path = '/content/drive/MyDrive/rf_model.pkl'\n",
        "\n",
        "# Save the trained Random Forest model to a pickle file in Google Drive\n",
        "with open(pickle_file_path, 'wb') as f:\n",
        "    pickle.dump(rf_model, f)\n",
        "\n",
        "print(\"Pickle file saved successfully at:\", pickle_file_path)\n"
      ],
      "metadata": {
        "id": "cgKn_2MfB3GR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from skimage import io\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained Random Forest model from the pickle file\n",
        "pickle_file_path = '/content/drive/MyDrive/rf_model.pkl'\n",
        "with open(pickle_file_path, 'rb') as f:\n",
        "    rf_model = pickle.load(f)\n",
        "\n",
        "# Load and preprocess the testing image\n",
        "image_path = '/content/drive/MyDrive/Dataset/Resized/train/battery_resized/battery10.jpg'\n",
        "test_image = io.imread(image_path)\n",
        "# Preprocess the image if necessary (resize, normalize, etc.)\n",
        "\n",
        "# Flatten the image into a feature vector\n",
        "test_features = test_image.flatten().reshape(1, -1)  # Reshape to a 2D array\n",
        "\n",
        "# Predict the class label for the testing image\n",
        "predicted_label_index = rf_model.predict(test_features)[0]\n",
        "\n",
        "# Decode the predicted label index to get the class label\n",
        "# Assuming you have a label encoder to map numerical labels back to original class labels\n",
        "predicted_class_label = label_encoder.inverse_transform([predicted_label_index])[0]\n",
        "\n",
        "print(\"Predicted class label:\", predicted_class_label)\n"
      ],
      "metadata": {
        "id": "y7WUxVkpB5ic"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}